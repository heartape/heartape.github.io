(window.webpackJsonp=window.webpackJsonp||[]).push([[49],{528:function(a,t,s){"use strict";s.r(t);var e=s(0),r=Object(e.a)({},(function(){var a=this,t=a._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":a.$parent.slotKey}},[t("h2",{attrs:{id:"_1-简介"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-简介"}},[a._v("#")]),a._v(" 1.简介")]),a._v(" "),t("p",[a._v("Kafka是一种高吞吐量、分布式、基于发布/订阅的消息系统，最初由LinkedIn公司开发，使用Scala语言编写，目前是Apache的开源项目。\nkafka在消息队列方面有很高的地位，因为其有极高的吞吐量，在大数据领域应用极广。")]),a._v(" "),t("h2",{attrs:{id:"_2-代码"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-代码"}},[a._v("#")]),a._v(" 2.代码")]),a._v(" "),t("blockquote",[t("p",[t("a",{attrs:{href:"https://github.com/heartape/study/tree/main/frame/kafka",target:"_blank",rel:"noopener noreferrer"}},[a._v("github"),t("OutboundLink")],1)])]),a._v(" "),t("h2",{attrs:{id:"_3-解析"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-解析"}},[a._v("#")]),a._v(" 3.解析")]),a._v(" "),t("p",[a._v("kafka能做到如此高的性能，因为其有许多好的设计，下面便一一解析。")]),a._v(" "),t("h3",{attrs:{id:"_1-生产者分区分配策略"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-生产者分区分配策略"}},[a._v("#")]),a._v(" 1.生产者分区分配策略")]),a._v(" "),t("h4",{attrs:{id:"roundrobin"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#roundrobin"}},[a._v("#")]),a._v(" RoundRobin")]),a._v(" "),t("p",[a._v("当生产者将消息放如到batch中时，会轮询partition依次放入消息。\n这样会有一个问题，即batch可能并没有装满便发送到消息队列，导致产生了更多的batch，消耗更多的资源。\n当然，在消息发送极快，partition数量较少，同时linger.ms设置较大时，则没有这方面的问题。")]),a._v(" "),t("h4",{attrs:{id:"sticky"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sticky"}},[a._v("#")]),a._v(" Sticky")]),a._v(" "),t("p",[a._v("当生产者将消息放如到batch中时，会优先装满当前batch，然后再到下一个partition。\n这样产生更少的batch，降低消息延时，减轻服务压力。\n有人会说，这样会导致partition间资源分配不均。\n其实在整体上去考虑的话，依旧是均衡的。")]),a._v(" "),t("h4",{attrs:{id:"其他"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#其他"}},[a._v("#")]),a._v(" 其他")]),a._v(" "),t("ul",[t("li",[a._v("手动指定分区。")]),a._v(" "),t("li",[a._v("未指定分区，但是设置了key，则根据序列化key使用murmur2哈希算法对分区数取模。")])]),a._v(" "),t("h3",{attrs:{id:"_2-消费者分区分配策略"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-消费者分区分配策略"}},[a._v("#")]),a._v(" 2.消费者分区分配策略")]),a._v(" "),t("h4",{attrs:{id:"range"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#range"}},[a._v("#")]),a._v(" Range")]),a._v(" "),t("p",[a._v("Range分配策略会以均分的方式分配partition，尽量使每个消费者消费的分区数量是均衡的。\nRange分配策略只作用于单个topic。")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("org.apache.kafka.clients.consumer.RangeAssignor\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("h4",{attrs:{id:"roundrobin-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#roundrobin-2"}},[a._v("#")]),a._v(" RoundRobin")]),a._v(" "),t("p",[a._v("RoundRobin分配策略与Range相似，主要不同点在于RoundRobin分配策略作用于所有topic。\nRoundRobin策略会将所有topic根据字典序排序，然后平均分配partition。")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("org.apache.kafka.clients.consumer.RoundRobinAssignor\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("h4",{attrs:{id:"sticky-2"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sticky-2"}},[a._v("#")]),a._v(" Sticky")]),a._v(" "),t("p",[a._v("Sticky分配策略与RoundRobin相似，主要不同点在于Sticky策略在发生Rebalance时，分区的分配尽量和上一次分配保持相同。")]),a._v(" "),t("div",{staticClass:"language- line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("org.apache.kafka.clients.consumer.StickyAssignor\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br")])]),t("p",[a._v("Sticky策略主要是为了优化之前ReBalance时，系统会暂停消费，导致stop the world。")]),a._v(" "),t("h4",{attrs:{id:"rebalance"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#rebalance"}},[a._v("#")]),a._v(" Rebalance")]),a._v(" "),t("p",[a._v("在Sticky策略之前，Rebalance流程大致如下：")]),a._v(" "),t("ul",[t("li",[a._v("添加consumer")]),a._v(" "),t("li",[a._v("consumer会向group发送请求")]),a._v(" "),t("li",[a._v("group发送Rebalance通知")]),a._v(" "),t("li",[a._v("所有consumer清除对partition的订阅状态，随后停止消费（stop the world）")]),a._v(" "),t("li",[a._v("所有consumer重新加入group")])]),a._v(" "),t("p",[a._v("Sticky主要优化点在于不会清除所有的订阅状态，而是只停止部分超出平均的partition的消费。")]),a._v(" "),t("div",{staticClass:"language-text line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[a._v("  ########  ########  ########         ########  ########  ######## \n  |  P1  |  |  P2  |  |  P3  |         |  P1  |  |  P2  |  |  P3  |\n  ########  ########  ########         ########  ########  ########\n        |    |            |      ===>      |        |          |\n       ########       ########         ########  ########  ######## \n       |  C1  |       |  C2  |         |  C1  |  |  C3  |  |  C2  |\n       ########       ########         ########  ########  ########\n可以看出，实际上只需要变动一个partition的订阅状态即可。\n")])]),a._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[a._v("1")]),t("br"),t("span",{staticClass:"line-number"},[a._v("2")]),t("br"),t("span",{staticClass:"line-number"},[a._v("3")]),t("br"),t("span",{staticClass:"line-number"},[a._v("4")]),t("br"),t("span",{staticClass:"line-number"},[a._v("5")]),t("br"),t("span",{staticClass:"line-number"},[a._v("6")]),t("br"),t("span",{staticClass:"line-number"},[a._v("7")]),t("br"),t("span",{staticClass:"line-number"},[a._v("8")]),t("br")])]),t("h3",{attrs:{id:"_3-pagecache"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-pagecache"}},[a._v("#")]),a._v(" 3.PageCache")]),a._v(" "),t("ul",[t("li",[a._v("kafka接收到生产者的消息后，通过mmap等方式减少内存拷贝（用户态到内核态的拷贝）。")]),a._v(" "),t("li",[a._v("kafka利用了操作系统提供的PageCache，无需管理内存，减少了gc压力。PageCache通过Radix tree搜索树来管理和搜索Page。")]),a._v(" "),t("li",[a._v("将消息在内存中的地址信息发送到socket缓冲区。")]),a._v(" "),t("li",[a._v("如果长时间没有命中被判定为冷数据，便会从内存中删除。")]),a._v(" "),t("li",[a._v("当消费到冷数据时，会从磁盘重新读取数据，并将周围数据一起读取，即所谓的预读。 因为在工程实践中发现，一旦用到一条数据，那么其周围数据大概率也会被用到，减少磁盘io。 另外，过多的partition可能导致服务器磁盘io性能的下降，因为不同partition之间不是连贯的，需要来回寻址。")]),a._v(" "),t("li",[a._v("最后，需要发送消费数据时通过DMA gather copy方式，根据socket缓冲区提供的地址信息，直接发送到网卡设备。")])]),a._v(" "),t("p",[a._v("是否由丢失数据的可能？\nkafka生产者在发送数据时有重试机制，成功发送到PageCache并且Follower成功从Leader拉取副本后，会返回成功应答。但注意此时数据都没有落盘。\nkafka官方不推荐增加flush()的频率，会极大降低性能，只推荐通过副本来尽力保证数据丢失，毕竟所有副本全部宕机是个极小概率事件。")]),a._v(" "),t("h3",{attrs:{id:"_4-offset"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-offset"}},[a._v("#")]),a._v(" 4.offset")]),a._v(" "),t("p",[a._v("Kafka对于offset的处理有两种提交方式")]),a._v(" "),t("ul",[t("li",[a._v("自动提交(默认): 由auto_commit_interval_ms控制提交频率。")]),a._v(" "),t("li",[a._v("手动提交: 同步手动提交、异步手动提交")])]),a._v(" "),t("p",[a._v("Kafka自带的topic(__consumer_offsets)用于提交偏移量，通过对每个 group.id 做哈希求模运算Math.abs(groupID.hashCode()) % numPartitions，从而将负载分散到不同的__consumer_offsets分区上。")]),a._v(" "),t("p",[a._v("一般为了吞吐量，都会使用自动提交的方式。因为同步手动提交会阻塞消费，而异步提交无法重试只能通过回调补救。\n自动提交主要缺点在于，如果存在已经消费但没有提交的消息时，服务宕机或者是网络问题导致的心跳发送失败导致Rebalance，会导致新的消费者从上一次提交的offset开始消费，造成重复消费。所以消费者需要一些幂等的设计。")])])}),[],!1,null,null,null);t.default=r.exports}}]);